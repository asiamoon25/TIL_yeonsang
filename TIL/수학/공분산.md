## 정의 

두 확률변수 간의 선형 관계의 강도와 방향을 측정하는 통계적 척도
	두 확률 변수 X와 Y의 대한 공분산은 보통 Cov(X,Y) 로 표시됨.
	$$Cov(X,Y) = E[(X-E[X])(Y-E[Y])]$$
	E[X] 는 확률변수 X의 기대값(평균)
	E[Y] 는 확률변수 Y의 기대값(평균)
	E[(X-E[X])(Y-E[Y])]는 X와 Y의 각각의 값이 해당 평균으로부터 얼마나 떨어져 있는지(편차) 의 곱의 기대값을 의미



## 성질

공분산은 5가지의 성질을 가짐.
1) 교환 법칙이 성립. 순서를 바꿔도 같음.
	$$Cov(X,Y) = Cov(Y,X)$$
2) 어떤 상수 a 와 다양한 값을 갖는 확률변수 X 의 공분산은 0, 상관관계가 없음.
	$$Cov(X,a) = 0\quad ,(a = constant)$$
3) 자신과의 공분산은 분산 Var(X) 와 같으며 0보다 큼.
	$$Cov(X,Y) = Var(X) \geq 0$$
4) 분배법칙이 성립함.
	$$Cov(X_1 + X_2,Y) = Cov(X_1, Y) + Cov(X_2,Y)$$
5) $E[aX] = aE[X]$ 이므로 공분산도 동일하게 가능함.
	$$Cov(aX,Y) = aCov(X,Y)$$
	$$\begin{align*}
	&Cov(aX,Y) = E[(cX-E[cX])(Y-E[Y])]\\
	&= E[c(X-E[X])(Y-E[Y])] \\
	&= cE[(X-E[X])(Y-E[Y])]\\
	&= cCov(X,Y)
	\end{align*}$$
6) 확률변수 X 와 Y가 서로 독립이라면 $E[XY] = E[X]E[Y]$ 이므로, 변수 X와 Y의 공분산은 0이다.
	$$\begin{flalign*}
	&Cov(X,Y) = E[XY] - E[X]E[Y] = 0\\
	&\because E[XY] = E[X]E[Y]
	\end{flalign*}$$

확률변수 X 또는 Y가 각각 평균이 0 이라면, $E[XY] = 0$ 이 됨.



## 공분산 행렬

**확률 변수 X 가 벡터인 경우**
	즉, 확률 벡터
	확률 벡터는 각 원소들이 스칼라 확률 변수라고 생각하면 됨.
	$$
	random \space vector X = \begin{pmatrix}
	X_{1}\\
	X_{2}\\
	\vdots\\
	X_{n}
	\end{pmatrix}
	\quad (X_1,X_2,X_3,\dots,X_n = random\space variables)
	$$

확률 벡터 X 에 대한 공분산 행렬을 다음과 같음.
$$
Cov(X,X) = E[(X-E[X])(X-E[X]^T)] = E[XX^T] - E[X]E[X^T] 
$$
$$
Cov(X,X) = 
\begin{pmatrix}
Cov(X_{1},X_{1}) &Cov(X_{1},X_{2}) & \dots & Cov(X_{1},X_{n})\\
Cov(X_{2},X_{1})&Cov(X_{2},X_{2}) & \dots & Cov(X_{2},X_{n})\\
\vdots&\vdots&\ddots&\vdots\\
Cov(X_{n},X_{1})&Cov(X_{n},X_{2})&\dots&Cov(X_{n},X_{n})
\end{pmatrix}
$$
$$
Cov(X,X) = 
\begin{pmatrix}
Var(X_1) &Cov(X_{1},X_{2}) & \dots & Cov(X_{1},X_{n})\\
Cov(X_{2},X_{1})&Var(X_{2}) & \dots & Cov(X_{2},X_{n})\\
\vdots&\vdots&\ddots&\vdots\\
Cov(X_{n},X_{1})&Cov(X_{n},X_{2})&\dots&Var(X_n)
\end{pmatrix}
$$
공분산의 정의 및 성질에 따라, 대각선 원소들은 확률 벡터의 $X_i$ 번째 원소의 분산이 됨.
$Cov(X_i,X_j) = Cov(X_j,X_i)$ 이므로 공분산 행렬을 **대칭 행렬** 이다.


**대각선 원소가 분산인 이유**
공분산 행렬에서 대각선 원소는 $Cov(X_i,X_j)$ 임. 이는 확률변수 $X_i$ 와 자기 자신 사이의 공분산을 의미.
공분산의 정의에 따라 이를 풀어서 쓰면 $Cov(X_i,X_j) = E[(X_i-E[X_i])^2]$ 이다.
이것은 바로 확률 변수 $X_i$ 의 분산의 정의와 일치함.
	_분산의 정의_
	$Var(X) =  E[(X-E[X])^2]$


## 교차 공분산 행렬

두 개의 다른 확률 벡터 X,Y 를 아래와 같이 둔다.
$$
random\space vector\space X =
\begin{pmatrix}
X_{1}\\
X_{2}\\
\vdots\\
X_{m}
\end{pmatrix}
\quad
random\space vector\space Y=
\begin{pmatrix}
Y_{1}\\
Y_{2}\\
\vdots\\
Y_{n}
\end{pmatrix}
$$
두 확률 벡터에 대한 공분산 행렬은 다음과 같다.
$$
\begin{align*}
&Cov(X,Y) = E[(X-E[X])(Y-E[Y])^T] = E[XY^T] - E[X]E[Y^T]\\\\\\
&Cov(X,Y)=
	\begin{pmatrix}
	Cov(X_1,Y_1)&Cov(X_1,Y_2)&\dots&Cov(X_1,Y_n)\\
	Cov(X2,Y1)&Cov(X2,Y2)&\dots&Cov(X2,Y_n)\\
	\vdots&\vdots&\ddots&\vdots\\
	Cov(X_m,Y1)&Cov(X_m,Y2)&\dots&Cov(X_m,Yn)
	\end{pmatrix}
\end{align*}
$$

이 경우에도, $Cov(X_i,X_j)=Cov(X_j,X_i)$ 는 성립하지만, m 과 n 이 같지 않은 경우에는 완전한 대칭 행렬이 되지는 않는다.
**성립하는 이유**
	공분산의 성질
		$Cov(X,Y) = E[(X-E[X])(Y-E[Y])]$
		곱셉 $ab = ba$ 이듯이 위치에 연관 받지 않는다. 선형성
		따라서 $Cov(X,Y) = Cov(Y,X)$ 가 성립한다.

## 공분산의 한계점
공분산은 아래와 같은 식으로 계산됨
$$
\begin{align*}
&Cov(X,Y) = E[(X-E[X])(Y-E[Y])]\\
&Cov(X,Y) = E[XY] - E[X]E[Y]
\end{align*}
$$

만약 확률 변수 X 와 Y의 측정 단위가 크게 다른경우
키와 몸무게를 측정하는데, 확률변수 X는 키 이지만 'm' 단위를 사용하고, 확률변수 Y 는 '몸무게' 인데 'g' 을 사용하면 X는 주로 1.0m ~ 2.0m 사이의 값을 가지고 Y는 40000 ~ 100000g 정도의 범위를 가진다. 이 경우 Y의 값이 영향이 매우 크게 나타나 공분산 값도 커진다.

몸무게를 g에서 kg 로 바꿔 넣어도 공분산 값도 바뀌게 된다.

공분산 값은 그 계산 결과 값의 부호(0보다 큰가 작은가)를 통해 상관관계의 방향(양인지 음인지 )만을 알려줌.

즉, 공분산 값의 크기 자체는 특별한 의미를 갖는다고 할 수 없다.


## 상관계수

공분산이 갖는 확률 변수의 절대적 크기(단위) 에 따른 영향을 제거 하여 정규화 시킨 것
	즉, 공분산을 각 확률 변수의 표준편차(분산의 제곱근) 의 곱으로 나누면, $-1< 상관계수 < 1$  의 값을 갖게 되고 확률 변수의 단위나 절대적인 크기 차이에 따른 영향을 받지 않게 됨.
		- 공분산의 한계점에서 나왔듯이 단위가 달라지면 공분산의 값이 달라지기 때문에 상관계수가 필요함.

**성질**
1) 상관계수의 절대 값은 1을 넘지 않는다.
2) 확률 변수 X,Y 가 독립이면 상관계수는 0이됨.
	공분산이 0이라는 뜻도 될듯하다.   
3) 반대로, 상관계수가 0이면 두 확률변수는 상관관계가 없다.
4) 상관계수가 0~1 사이이면 양의 상관관계, -1 ~ 0 사이이면 음의 상관관계를 가짐


**상관계수를 구하는 식**
두 변수 (x,y) 에 대하여 관측값 n개의 짝$(x_1,y_1), (x_2,y_2), \dots,(x_n,y_n)$ 다음과 같이 계산된다.
$$
\begin{align*}
&r = \frac{S_{xy}}{\sqrt{S_{xx}}\sqrt{S_{yy}}}\\\\
&but\\\\
&\widetilde{x} = \frac{1}{n} \sum_

\end{align*}

$$