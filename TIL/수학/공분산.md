## 정의 

두 확률변수 간의 선형 관계의 강도와 방향을 측정하는 통계적 척도
	두 확률 변수 X와 Y의 대한 공분산은 보통 Cov(X,Y) 로 표시됨.
	$$Cov(X,Y) = E[(X-E[X])(Y-E[Y])]$$
	E[X] 는 확률변수 X의 기대값(평균)
	E[Y] 는 확률변수 Y의 기대값(평균)
	E[(X-E[X])(Y-E[Y])]는 X와 Y의 각각의 값이 해당 평균으로부터 얼마나 떨어져 있는지(편차) 의 곱의 기대값을 의미



## 성질

공분산은 5가지의 성질을 가짐.
1) 교환 법칙이 성립. 순서를 바꿔도 같음.
	$$Cov(X,Y) = Cov(Y,X)$$
2) 어떤 상수 a 와 다양한 값을 갖는 확률변수 X 의 공분산은 0, 상관관계가 없음.
	$$Cov(X,a) = 0\quad ,(a = constant)$$
3) 자신과의 공분산은 분산 Var(X) 와 같으며 0보다 큼.
	$$Cov(X,Y) = Var(X) \geq 0$$
4) 분배법칙이 성립함.
	$$Cov(X_1 + X_2,Y) = Cov(X_1, Y) + Cov(X_2,Y)$$
5) $E[aX] = aE[X]$ 이므로 공분산도 동일하게 가능함.
	$$Cov(aX,Y) = aCov(X,Y)$$
	$$\begin{align*}
	&Cov(aX,Y) = E[(cX-E[cX])(Y-E[Y])]\\
	&= E[c(X-E[X])(Y-E[Y])] \\
	&= cE[(X-E[X])(Y-E[Y])]\\
	&= cCov(X,Y)
	\end{align*}$$
6) 확률변수 X 와 Y가 서로 독립이라면 $E[XY] = E[X]E[Y]$ 이므로, 변수 X와 Y의 공분산은 0이다.
	$$\begin{flalign*}
	&Cov(X,Y) = E[XY] - E[X]E[Y] = 0\\
	&\because E[XY] = E[X]E[Y]
	\end{flalign*}$$

확률변수 X 또는 Y가 각각 평균이 0 이라면, $E[XY] = 0$ 이 됨.



## 공분산 행렬

**확률 변수 X 가 벡터인 경우**
	즉, 확률 벡터
	확률 벡터는 각 원소들이 스칼라 확률 변수라고 생각하면 됨.
	$$
	random \space vector X = \begin{pmatrix}
	X_{1}\\
	X_{2}\\
	\vdots\\
	X_{n}
	\end{pmatrix}
	\quad (X_1,X_2,X_3,\dots,X_n = random\space variables)
	$$

확률 벡터 X 에 대한 공분산 행렬을 다음과 같음.
$$
Cov(X,X) = E[(X-E[X])(X-E[X]^T)] = E[XX^T] - E[X]E[X^T] 
$$
$$
Cov(X,X) = 
\begin{pmatrix}
Cov(X_{1},X_{1}) &Cov(X_{1},X_{2}) & \dots & Cov(X_{1},X_{n})\\
Cov(X_{2},X_{1})&Cov(X_{2},X_{2}) & \dots & Cov(X_{2},X_{n})\\
\vdots&\vdots&\ddots&\vdots\\
Cov(X_{n},X_{1})&Cov(X_{n},X_{2})&\dots&Cov(X_{n},X_{n})
\end{pmatrix}
$$
$$
Cov(X,X) = 
\begin{pmatrix}
Var(X_1) &Cov(X_{1},X_{2}) & \dots & Cov(X_{1},X_{n})\\
Cov(X_{2},X_{1})&Var(X_{2}) & \dots & Cov(X_{2},X_{n})\\
\vdots&\vdots&\ddots&\vdots\\
Cov(X_{n},X_{1})&Cov(X_{n},X_{2})&\dots&Var(X_n)
\end{pmatrix}
$$
공분산의 정의 및 성질에 따라, 대각선 원소들은 확률 벡터의 $X_i$ 번째 원소의 분산이 됨.
$Cov(X_i,X_j) = Cov(X_j,X_i)$ 이므로 공분산 행렬을 **대칭 행렬** 이다.


**대각선 원소가 분산인 이유**
공분산 행렬에서 대각선 원소는 $Cov(X_i,X_j)$ 임. 이는 확률변수 $X_i$ 와 자기 자신 사이의 공분산을 의미.
공분산의 정의에 따라 이를 풀어서 쓰면 $Cov(X_i,X_j) = E[(X_i-E[X_i])^2]$ 이다.
이것은 바로 확률 변수 $X_i$ 의 분산의 정의와 일치함.
	_분산의 정의_
	$Var(X) =  E[(X-E[X])^2]$


## 교차 공분산 행렬

두 개의 다른 확률 벡터 X,Y 를 아래와 같이 둔다.
$$
random\space vector\space X =
\begin{pmatrix}
X_{1}\\
X_{2}\\
\vdots\\
X_{m}
\end{pmatrix}
\quad
random\space vector\space Y=
\begin{pmatrix}
Y_{1}\\
Y_{2}\\
\vdots\\
Y_{n}
\end{pmatrix}
$$
두 확률 벡터에 대한 공분산 행렬은 다음과 같다.
$$
\begin{align*}
&Cov(X,Y) = E[(X-E[X])(Y-E[Y])^T] = E[XY^T] - E[X]E[Y^T]\\\\\\
&Cov(X,Y)=
	\begin{pmatrix}
	Cov(X_1,Y_1)&Cov(X_1,Y_2)&\dots&Cov(X_1,Y_n)\\
	Cov(X2,Y1)&Cov(X2,Y2)&\dots&Cov(X2,Y_n)\\
	\vdots&\vdots&\ddots&\vdots\\
	Cov(X_m,Y1)&Cov(X_m,Y2)&\dots&Cov(X_m,Yn)
	\end{pmatrix}
\end{align*}
$$

이 경우에도, $Cov(X_i,X_j)=Cov(X_j,X_i)$ 는 성립하지만, m 과 n 이 같지 않은 경우에는 완전한 대칭 행렬이 되지는 않는다.