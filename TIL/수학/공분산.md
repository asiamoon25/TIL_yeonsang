## 정의 

두 확률변수 간의 선형 관계의 강도와 방향을 측정하는 통계적 척도
	두 확률 변수 X와 Y의 대한 공분산은 보통 Cov(X,Y) 로 표시됨.
	$$Cov(X,Y) = E[(X-E[X])(Y-E[Y])]$$
	E[X] 는 확률변수 X의 기대값(평균)
	E[Y] 는 확률변수 Y의 기대값(평균)
	E[(X-E[X])(Y-E[Y])]는 X와 Y의 각각의 값이 해당 평균으로부터 얼마나 떨어져 있는지(편차) 의 곱의 기대값을 의미



## 성질

공분산은 5가지의 성질을 가짐.
1) 교환 법칙이 성립. 순서를 바꿔도 같음.
	$$Cov(X,Y) = Cov(Y,X)$$
2) 어떤 상수 a 와 다양한 값을 갖는 확률변수 X 의 공분산은 0, 상관관계가 없음.
	$$Cov(X,a) = 0\quad ,(a = constant)$$
3) 자신과의 공분산은 분산 Var(X) 와 같으며 0보다 큼.
	$$Cov(X,Y) = Var(X) \geq 0$$
4) 분배법칙이 성립함.
	$$Cov(X_1 + X_2,Y) = Cov(X_1, Y) + Cov(X_2,Y)$$
5) $E[aX] = aE[X]$ 이므로 공분산도 동일하게 가능함.
	$$Cov(aX,Y) = aCov(X,Y)$$
	$$\begin{align*}
	&Cov(aX,Y) = E[(cX-E[cX])(Y-E[Y])]\\
	&= E[c(X-E[X])(Y-E[Y])] \\
	&= cE[(X-E[X])(Y-E[Y])]\\
	&= cCov(X,Y)
	\end{align*}$$
6) 확률변수 X 와 Y가 서로 독립이라면 $E[XY] = E[X]E[Y]$ 이므로, 변수 X와 Y의 공분산은 0이다.
	$$\begin{flalign*}
	&Cov(X,Y) = E[XY] - E[X]E[Y] = 0\\
	&\because E[XY] = E[X]E[Y]
	\end{flalign*}$$

확률변수 X 또는 Y가 각각 평균이 0 이라면, $E[XY] = 0$ 이 됨.



## 공분산 행렬

**확률 변수 X 가 벡터인 경우**
	즉, 확률 벡터
	확률 벡터는 각 원소들이 스칼라 확률 변수라고 생각하면 됨.
	$$
	random \space vector X = \begin{pmatrix}
	X_{1}\\
	X_{2}\\
	\vdots\\
	X_{n}
	\end{pmatrix}
	\quad (X_1,X_2,X_3,\dots,X_n = random\space variables)
	$$

확률 벡터 X 에 대한 공분산 행렬을 다음과 같음.
$$
Cov(X,X) = E[(X-E[X])(X-E[X]^T)] = E[XX^T] - E[X]E[X^T] 
$$
$$
Cov(X,X) = 
\begin{pmatrix}
Cov(X_{1},X_{1}) &Cov(X_{1},X_{2}) & \dots & Cov(X_{1},X_{n})\\
Cov(X_{2},X_{1})&Cov(X_{2},X_{2}) & \dots & Cov(X_{2},X_{n})\\
\vdots&\vdots&\ddots&\vdots\\
Cov(X_{n},X_{1})&Cov(X_{n},X_{2})&\dots&Cov(X_{n},X_{n})
\end{pmatrix}
$$
$$
Cov(X,X) = 
\begin{pmatrix}
Var(X_1) &Cov(X_{1},X_{2}) & \dots & Cov(X_{1},X_{n})\\
Cov(X_{2},X_{1})&Var(X_{2}) & \dots & Cov(X_{2},X_{n})\\
\vdots&\vdots&\ddots&\vdots\\
Cov(X_{n},X_{1})&Cov(X_{n},X_{2})&\dots&Var(X_n)
\end{pmatrix}
$$
공분산의 정의 및 성질에 따라, 대각선 원소들은 확률 벡터의 $X_i$ 번째 원소의 분산이 됨.
$Cov(X_i,X_j) = Cov(X_j,X_i)$ 이므로 공분산 행렬을 **대칭 행렬** 이다.