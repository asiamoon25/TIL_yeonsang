* 매우 많은 피처로 구성된 다차원 데이터 세트의 차원을 축소해 새로운 차원의 데이터 세트를 생성
	일반적으로 차원축소는 피처 선택과 피처 추출로 나눌 수 있음.
	
	피처 선택
		특정 피처에 종속성이 강한 불필요한 피처는 제거
		장점은 피처의 해석이 용이함.
		단점은 피처간 상관관계를 고려하기 어렵다는 점.
	피처 추출
		기존 피처를 저차원의 중요 피처로 압축해서 추출하는 것
		기존의 피처와는 완전이 다른 값이 됨.
		장점은 피처 간 상관관계를 고려하기 용이함.
		단점은 추출된 변수의 해석이 어려움.


### PCA
가장 대표적인 차원 축소 기법
_데이터들의 공분산 행렬에 대한 특이값 분해(SVD) 로 볼 수 있음._
PCA 기법의 핵심은 **데이터를 축에 사영했을 때 가장 높은 분산을 가지는 데이터의 축을 찾아 그 축으로 차원을 축소**  해당 축을 **주성분**이라고 한다.

높은 분산을 가지는 축을 찾는 이유 => **정보의 손실을 최소화** 하기 위해서

_분산이 크다는 것 -> 원래 데이터의 분포를 잘 설명할 수 있다는 것을 뜻함._

![[Pasted image 20231227154804.png]]

데이터를 좌측 축에 사영시키는 것이 데이터의 원래 분포를 잘 설명한다고 볼 수 있음.

PCA 는 제일 먼저 **가장 큰 분산을 기반으로 첫번째 축을 생성**, 두번째 축으로 **이 벡터 축에 직각이 되는 벡터를 축**으로 함. 그리고 세번째 축은 **다시 두번째 축과 직각이 되는 벡터를 축으로 설정**하는 방식으로 축을 생성함.

이렇게 생성된 벡터 축에 원본 데이터를 투영하면 벡터축의 갯수만큼 차원으로 원본 데이터가 차원 축소됨.

#### 왜 직각?
첫 번째 축에 데이터를 사영했는데 같은 점으로 겹쳐서 사영된 데이터가 10개 있으면 첫번째 축으로는 데이터를 모두 설명할 수 없게 됨. -> 다른축이 필요

이때 직각인 축으로 사영하게 되면 겹쳤던 10개의 데이터는 절대 같은 점으로 사영 될 수 없고 두번째 축이 이 10개의 데이터를 설명할 수 있음.

이런 원리로 계속 직교하는 축을 다음 축으로 설정하는 방식으로 축을 생성하게 됨.

_직각으로 만드는 이유  [주성분분석](obsidian://open?vault=TIL_yeonsang&file=TIL%2F%EC%88%98%ED%95%99%2F%EC%A3%BC%EC%84%B1%EB%B6%84%20%EB%B6%84%EC%84%9D)_


#### 축을 찾는 방법
입력 데이터의 **공분산 행렬을 고유값 분해** 했을 때 구해진 **고유벡터** 가 **PCA의 주성분 벡터** 로써 입력 데이터의 **분산이 큰 방향** 을 나타냄.

_[공분산](https://kh-mo.github.io/notation/2021/01/02/covariance/) 관련 지식_

**고유값** 이 **고유벡터의 크기를 나타내고 입력 데이터의 분산**을 나타냄.

공분산은 두 변수 간의 변동을 의미하고 고유 벡터는 n x n 행렬 A에 대해서 $Ax = ax$ (a)